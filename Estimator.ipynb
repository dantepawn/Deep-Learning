{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Estimator.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMDBBUAb6nrk3rUAWW/d5Vx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dantepawn/Deep-Learning/blob/master/Estimator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYtaq-cAjyIG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhChB0Wgj2UQ",
        "colab_type": "text"
      },
      "source": [
        "# Estimators"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GI_mz21kEy7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "779f700e-b745-47d7-e6e9-8560776470a7"
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJGTUfpxj7lW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import tensorflow as tf\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTUh40rXj_PP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fbdb = tf.keras.utils.get_file('I1.csv','http://www.football-data.co.uk/mmz4281/1819/I1.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BeArJlouk0yf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fb = pd.read_csv(fbdb)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HI_k90DIlbkO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "57acb50e-4f7f-416a-82b9-31093ae571b3"
      },
      "source": [
        "fb['FTR'].value_counts()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "H    166\n",
              "D    108\n",
              "A    106\n",
              "Name: FTR, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsETzsLJlyqu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train  = fb.drop(['FTR'] , axis = 1)\n",
        "target = fb['FTR']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ze-T-S7_vMzG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target.replace({'H':0,'D':1,'A':2}, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bvtbKi7vNt6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "9d061747-0260-422f-acfb-d8845ba2f96b"
      },
      "source": [
        "target"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      A\n",
              "1      A\n",
              "2      A\n",
              "3      H\n",
              "4      D\n",
              "      ..\n",
              "375    H\n",
              "376    H\n",
              "377    H\n",
              "378    A\n",
              "379    H\n",
              "Name: FTR, Length: 380, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtPmCqoNvOLL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7zmz4-gmSvH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "outputId": "14769149-1c18-4f64-8297-25ab7c85518a"
      },
      "source": [
        "train.columns"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Div', 'Date', 'HomeTeam', 'AwayTeam', 'FTHG', 'FTAG', 'HTHG', 'HTAG',\n",
              "       'HTR', 'HS', 'AS', 'HST', 'AST', 'HF', 'AF', 'HC', 'AC', 'HY', 'AY',\n",
              "       'HR', 'AR', 'B365H', 'B365D', 'B365A', 'BWH', 'BWD', 'BWA', 'IWH',\n",
              "       'IWD', 'IWA', 'PSH', 'PSD', 'PSA', 'WHH', 'WHD', 'WHA', 'VCH', 'VCD',\n",
              "       'VCA', 'Bb1X2', 'BbMxH', 'BbAvH', 'BbMxD', 'BbAvD', 'BbMxA', 'BbAvA',\n",
              "       'BbOU', 'BbMx>2.5', 'BbAv>2.5', 'BbMx<2.5', 'BbAv<2.5', 'BbAH', 'BbAHh',\n",
              "       'BbMxAHH', 'BbAvAHH', 'BbMxAHA', 'BbAvAHA', 'PSCH', 'PSCD', 'PSCA'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lgj855Eum2Jv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "4dc6bac7-8d3b-4d54-f467-97fc5a39f476"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Div</th>\n",
              "      <th>Date</th>\n",
              "      <th>HomeTeam</th>\n",
              "      <th>AwayTeam</th>\n",
              "      <th>FTHG</th>\n",
              "      <th>FTAG</th>\n",
              "      <th>HTHG</th>\n",
              "      <th>HTAG</th>\n",
              "      <th>HTR</th>\n",
              "      <th>HS</th>\n",
              "      <th>AS</th>\n",
              "      <th>HST</th>\n",
              "      <th>AST</th>\n",
              "      <th>HF</th>\n",
              "      <th>AF</th>\n",
              "      <th>HC</th>\n",
              "      <th>AC</th>\n",
              "      <th>HY</th>\n",
              "      <th>AY</th>\n",
              "      <th>HR</th>\n",
              "      <th>AR</th>\n",
              "      <th>B365H</th>\n",
              "      <th>B365D</th>\n",
              "      <th>B365A</th>\n",
              "      <th>BWH</th>\n",
              "      <th>BWD</th>\n",
              "      <th>BWA</th>\n",
              "      <th>IWH</th>\n",
              "      <th>IWD</th>\n",
              "      <th>IWA</th>\n",
              "      <th>PSH</th>\n",
              "      <th>PSD</th>\n",
              "      <th>PSA</th>\n",
              "      <th>WHH</th>\n",
              "      <th>WHD</th>\n",
              "      <th>WHA</th>\n",
              "      <th>VCH</th>\n",
              "      <th>VCD</th>\n",
              "      <th>VCA</th>\n",
              "      <th>Bb1X2</th>\n",
              "      <th>BbMxH</th>\n",
              "      <th>BbAvH</th>\n",
              "      <th>BbMxD</th>\n",
              "      <th>BbAvD</th>\n",
              "      <th>BbMxA</th>\n",
              "      <th>BbAvA</th>\n",
              "      <th>BbOU</th>\n",
              "      <th>BbMx&gt;2.5</th>\n",
              "      <th>BbAv&gt;2.5</th>\n",
              "      <th>BbMx&lt;2.5</th>\n",
              "      <th>BbAv&lt;2.5</th>\n",
              "      <th>BbAH</th>\n",
              "      <th>BbAHh</th>\n",
              "      <th>BbMxAHH</th>\n",
              "      <th>BbAvAHH</th>\n",
              "      <th>BbMxAHA</th>\n",
              "      <th>BbAvAHA</th>\n",
              "      <th>PSCH</th>\n",
              "      <th>PSCD</th>\n",
              "      <th>PSCA</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I1</td>\n",
              "      <td>18/08/2018</td>\n",
              "      <td>Chievo</td>\n",
              "      <td>Juventus</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>D</td>\n",
              "      <td>7</td>\n",
              "      <td>23</td>\n",
              "      <td>2</td>\n",
              "      <td>11</td>\n",
              "      <td>7</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13.00</td>\n",
              "      <td>5.75</td>\n",
              "      <td>1.25</td>\n",
              "      <td>14.00</td>\n",
              "      <td>6.25</td>\n",
              "      <td>1.22</td>\n",
              "      <td>13.00</td>\n",
              "      <td>5.80</td>\n",
              "      <td>1.25</td>\n",
              "      <td>15.87</td>\n",
              "      <td>6.21</td>\n",
              "      <td>1.25</td>\n",
              "      <td>13.00</td>\n",
              "      <td>6.00</td>\n",
              "      <td>1.22</td>\n",
              "      <td>15.00</td>\n",
              "      <td>6.00</td>\n",
              "      <td>1.25</td>\n",
              "      <td>41</td>\n",
              "      <td>15.87</td>\n",
              "      <td>13.70</td>\n",
              "      <td>6.44</td>\n",
              "      <td>5.88</td>\n",
              "      <td>1.27</td>\n",
              "      <td>1.24</td>\n",
              "      <td>38</td>\n",
              "      <td>1.75</td>\n",
              "      <td>1.70</td>\n",
              "      <td>2.24</td>\n",
              "      <td>2.13</td>\n",
              "      <td>19</td>\n",
              "      <td>2.00</td>\n",
              "      <td>1.68</td>\n",
              "      <td>1.64</td>\n",
              "      <td>2.38</td>\n",
              "      <td>2.29</td>\n",
              "      <td>18.84</td>\n",
              "      <td>6.42</td>\n",
              "      <td>1.22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I1</td>\n",
              "      <td>18/08/2018</td>\n",
              "      <td>Lazio</td>\n",
              "      <td>Napoli</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>D</td>\n",
              "      <td>9</td>\n",
              "      <td>11</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.40</td>\n",
              "      <td>2.50</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.50</td>\n",
              "      <td>2.45</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.55</td>\n",
              "      <td>2.40</td>\n",
              "      <td>2.90</td>\n",
              "      <td>3.59</td>\n",
              "      <td>2.48</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.50</td>\n",
              "      <td>2.40</td>\n",
              "      <td>2.88</td>\n",
              "      <td>3.40</td>\n",
              "      <td>2.50</td>\n",
              "      <td>41</td>\n",
              "      <td>2.95</td>\n",
              "      <td>2.82</td>\n",
              "      <td>3.65</td>\n",
              "      <td>3.50</td>\n",
              "      <td>2.56</td>\n",
              "      <td>2.44</td>\n",
              "      <td>38</td>\n",
              "      <td>1.74</td>\n",
              "      <td>1.68</td>\n",
              "      <td>2.29</td>\n",
              "      <td>2.17</td>\n",
              "      <td>20</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.12</td>\n",
              "      <td>2.07</td>\n",
              "      <td>1.83</td>\n",
              "      <td>1.79</td>\n",
              "      <td>2.78</td>\n",
              "      <td>3.57</td>\n",
              "      <td>2.59</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I1</td>\n",
              "      <td>19/08/2018</td>\n",
              "      <td>Bologna</td>\n",
              "      <td>Spal</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>D</td>\n",
              "      <td>8</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>16</td>\n",
              "      <td>11</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2.25</td>\n",
              "      <td>3.20</td>\n",
              "      <td>3.40</td>\n",
              "      <td>2.25</td>\n",
              "      <td>3.20</td>\n",
              "      <td>3.40</td>\n",
              "      <td>2.25</td>\n",
              "      <td>3.10</td>\n",
              "      <td>3.45</td>\n",
              "      <td>2.32</td>\n",
              "      <td>3.16</td>\n",
              "      <td>3.58</td>\n",
              "      <td>2.25</td>\n",
              "      <td>3.20</td>\n",
              "      <td>3.30</td>\n",
              "      <td>2.25</td>\n",
              "      <td>3.10</td>\n",
              "      <td>3.70</td>\n",
              "      <td>41</td>\n",
              "      <td>2.39</td>\n",
              "      <td>2.27</td>\n",
              "      <td>3.21</td>\n",
              "      <td>3.12</td>\n",
              "      <td>3.70</td>\n",
              "      <td>3.44</td>\n",
              "      <td>38</td>\n",
              "      <td>2.43</td>\n",
              "      <td>2.34</td>\n",
              "      <td>1.65</td>\n",
              "      <td>1.58</td>\n",
              "      <td>19</td>\n",
              "      <td>-0.25</td>\n",
              "      <td>1.97</td>\n",
              "      <td>1.92</td>\n",
              "      <td>1.99</td>\n",
              "      <td>1.94</td>\n",
              "      <td>2.31</td>\n",
              "      <td>3.18</td>\n",
              "      <td>3.59</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I1</td>\n",
              "      <td>19/08/2018</td>\n",
              "      <td>Empoli</td>\n",
              "      <td>Cagliari</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>H</td>\n",
              "      <td>9</td>\n",
              "      <td>12</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>19</td>\n",
              "      <td>19</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.14</td>\n",
              "      <td>3.20</td>\n",
              "      <td>3.60</td>\n",
              "      <td>2.15</td>\n",
              "      <td>3.25</td>\n",
              "      <td>3.60</td>\n",
              "      <td>2.15</td>\n",
              "      <td>3.30</td>\n",
              "      <td>3.45</td>\n",
              "      <td>2.22</td>\n",
              "      <td>3.26</td>\n",
              "      <td>3.60</td>\n",
              "      <td>2.25</td>\n",
              "      <td>3.25</td>\n",
              "      <td>3.25</td>\n",
              "      <td>2.25</td>\n",
              "      <td>3.13</td>\n",
              "      <td>3.60</td>\n",
              "      <td>41</td>\n",
              "      <td>2.34</td>\n",
              "      <td>2.22</td>\n",
              "      <td>3.35</td>\n",
              "      <td>3.23</td>\n",
              "      <td>3.65</td>\n",
              "      <td>3.43</td>\n",
              "      <td>38</td>\n",
              "      <td>2.22</td>\n",
              "      <td>2.11</td>\n",
              "      <td>1.78</td>\n",
              "      <td>1.71</td>\n",
              "      <td>19</td>\n",
              "      <td>-0.25</td>\n",
              "      <td>1.98</td>\n",
              "      <td>1.91</td>\n",
              "      <td>1.98</td>\n",
              "      <td>1.94</td>\n",
              "      <td>2.54</td>\n",
              "      <td>3.42</td>\n",
              "      <td>2.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I1</td>\n",
              "      <td>19/08/2018</td>\n",
              "      <td>Parma</td>\n",
              "      <td>Udinese</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>H</td>\n",
              "      <td>9</td>\n",
              "      <td>16</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>10</td>\n",
              "      <td>13</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.45</td>\n",
              "      <td>3.30</td>\n",
              "      <td>2.90</td>\n",
              "      <td>2.45</td>\n",
              "      <td>3.20</td>\n",
              "      <td>3.00</td>\n",
              "      <td>2.45</td>\n",
              "      <td>3.15</td>\n",
              "      <td>3.05</td>\n",
              "      <td>2.51</td>\n",
              "      <td>3.20</td>\n",
              "      <td>3.18</td>\n",
              "      <td>2.50</td>\n",
              "      <td>3.20</td>\n",
              "      <td>2.90</td>\n",
              "      <td>2.60</td>\n",
              "      <td>3.10</td>\n",
              "      <td>3.00</td>\n",
              "      <td>41</td>\n",
              "      <td>2.60</td>\n",
              "      <td>2.47</td>\n",
              "      <td>3.30</td>\n",
              "      <td>3.17</td>\n",
              "      <td>3.18</td>\n",
              "      <td>3.00</td>\n",
              "      <td>38</td>\n",
              "      <td>2.34</td>\n",
              "      <td>2.21</td>\n",
              "      <td>1.73</td>\n",
              "      <td>1.65</td>\n",
              "      <td>20</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.81</td>\n",
              "      <td>1.77</td>\n",
              "      <td>2.18</td>\n",
              "      <td>2.10</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.24</td>\n",
              "      <td>2.78</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Div        Date HomeTeam  AwayTeam  FTHG  ...  BbMxAHA  BbAvAHA   PSCH  PSCD  PSCA\n",
              "0  I1  18/08/2018   Chievo  Juventus     2  ...     2.38     2.29  18.84  6.42  1.22\n",
              "1  I1  18/08/2018    Lazio    Napoli     1  ...     1.83     1.79   2.78  3.57  2.59\n",
              "2  I1  19/08/2018  Bologna      Spal     0  ...     1.99     1.94   2.31  3.18  3.59\n",
              "3  I1  19/08/2018   Empoli  Cagliari     2  ...     1.98     1.94   2.54  3.42  2.95\n",
              "4  I1  19/08/2018    Parma   Udinese     2  ...     2.18     2.10   2.80  3.24  2.78\n",
              "\n",
              "[5 rows x 60 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCD9X50xnDFy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feats = [ 'BbMxH', 'BbAvH', 'BbMxD', 'BbAvD', 'BbMxA', 'BbAvA',  'BbAHh', 'BbMxAHH', 'BbAvAHH', 'BbMxAHA', 'BbAvAHA', 'PSCH', 'PSCD', 'PSCA']\n",
        "feats.extend('B365H\tB365D\tB365A\tBWH\tBWD\tBWA\tIWH\tIWD\tIWA\tPSH\tPSD\tPSA\tWHH\tWHD\tWHA\tVCH\tVCD\tVCA'.split())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FqMVXWboZ01",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = train[feats]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-zs6Y-O0ovU6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "283f5b9e-7c14-4425-b07f-fc6f147869a4"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>BbMxH</th>\n",
              "      <th>BbAvH</th>\n",
              "      <th>BbMxD</th>\n",
              "      <th>BbAvD</th>\n",
              "      <th>BbMxA</th>\n",
              "      <th>BbAvA</th>\n",
              "      <th>BbAHh</th>\n",
              "      <th>BbMxAHH</th>\n",
              "      <th>BbAvAHH</th>\n",
              "      <th>BbMxAHA</th>\n",
              "      <th>BbAvAHA</th>\n",
              "      <th>PSCH</th>\n",
              "      <th>PSCD</th>\n",
              "      <th>PSCA</th>\n",
              "      <th>B365H</th>\n",
              "      <th>B365D</th>\n",
              "      <th>B365A</th>\n",
              "      <th>BWH</th>\n",
              "      <th>BWD</th>\n",
              "      <th>BWA</th>\n",
              "      <th>IWH</th>\n",
              "      <th>IWD</th>\n",
              "      <th>IWA</th>\n",
              "      <th>PSH</th>\n",
              "      <th>PSD</th>\n",
              "      <th>PSA</th>\n",
              "      <th>WHH</th>\n",
              "      <th>WHD</th>\n",
              "      <th>WHA</th>\n",
              "      <th>VCH</th>\n",
              "      <th>VCD</th>\n",
              "      <th>VCA</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>15.87</td>\n",
              "      <td>13.70</td>\n",
              "      <td>6.44</td>\n",
              "      <td>5.88</td>\n",
              "      <td>1.27</td>\n",
              "      <td>1.24</td>\n",
              "      <td>2.00</td>\n",
              "      <td>1.68</td>\n",
              "      <td>1.64</td>\n",
              "      <td>2.38</td>\n",
              "      <td>2.29</td>\n",
              "      <td>18.84</td>\n",
              "      <td>6.42</td>\n",
              "      <td>1.22</td>\n",
              "      <td>13.00</td>\n",
              "      <td>5.75</td>\n",
              "      <td>1.25</td>\n",
              "      <td>14.00</td>\n",
              "      <td>6.25</td>\n",
              "      <td>1.22</td>\n",
              "      <td>13.00</td>\n",
              "      <td>5.80</td>\n",
              "      <td>1.25</td>\n",
              "      <td>15.87</td>\n",
              "      <td>6.21</td>\n",
              "      <td>1.25</td>\n",
              "      <td>13.00</td>\n",
              "      <td>6.00</td>\n",
              "      <td>1.22</td>\n",
              "      <td>15.00</td>\n",
              "      <td>6.00</td>\n",
              "      <td>1.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.95</td>\n",
              "      <td>2.82</td>\n",
              "      <td>3.65</td>\n",
              "      <td>3.50</td>\n",
              "      <td>2.56</td>\n",
              "      <td>2.44</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.12</td>\n",
              "      <td>2.07</td>\n",
              "      <td>1.83</td>\n",
              "      <td>1.79</td>\n",
              "      <td>2.78</td>\n",
              "      <td>3.57</td>\n",
              "      <td>2.59</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.40</td>\n",
              "      <td>2.50</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.50</td>\n",
              "      <td>2.45</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.55</td>\n",
              "      <td>2.40</td>\n",
              "      <td>2.90</td>\n",
              "      <td>3.59</td>\n",
              "      <td>2.48</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.50</td>\n",
              "      <td>2.40</td>\n",
              "      <td>2.88</td>\n",
              "      <td>3.40</td>\n",
              "      <td>2.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.39</td>\n",
              "      <td>2.27</td>\n",
              "      <td>3.21</td>\n",
              "      <td>3.12</td>\n",
              "      <td>3.70</td>\n",
              "      <td>3.44</td>\n",
              "      <td>-0.25</td>\n",
              "      <td>1.97</td>\n",
              "      <td>1.92</td>\n",
              "      <td>1.99</td>\n",
              "      <td>1.94</td>\n",
              "      <td>2.31</td>\n",
              "      <td>3.18</td>\n",
              "      <td>3.59</td>\n",
              "      <td>2.25</td>\n",
              "      <td>3.20</td>\n",
              "      <td>3.40</td>\n",
              "      <td>2.25</td>\n",
              "      <td>3.20</td>\n",
              "      <td>3.40</td>\n",
              "      <td>2.25</td>\n",
              "      <td>3.10</td>\n",
              "      <td>3.45</td>\n",
              "      <td>2.32</td>\n",
              "      <td>3.16</td>\n",
              "      <td>3.58</td>\n",
              "      <td>2.25</td>\n",
              "      <td>3.20</td>\n",
              "      <td>3.30</td>\n",
              "      <td>2.25</td>\n",
              "      <td>3.10</td>\n",
              "      <td>3.70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.34</td>\n",
              "      <td>2.22</td>\n",
              "      <td>3.35</td>\n",
              "      <td>3.23</td>\n",
              "      <td>3.65</td>\n",
              "      <td>3.43</td>\n",
              "      <td>-0.25</td>\n",
              "      <td>1.98</td>\n",
              "      <td>1.91</td>\n",
              "      <td>1.98</td>\n",
              "      <td>1.94</td>\n",
              "      <td>2.54</td>\n",
              "      <td>3.42</td>\n",
              "      <td>2.95</td>\n",
              "      <td>2.14</td>\n",
              "      <td>3.20</td>\n",
              "      <td>3.60</td>\n",
              "      <td>2.15</td>\n",
              "      <td>3.25</td>\n",
              "      <td>3.60</td>\n",
              "      <td>2.15</td>\n",
              "      <td>3.30</td>\n",
              "      <td>3.45</td>\n",
              "      <td>2.22</td>\n",
              "      <td>3.26</td>\n",
              "      <td>3.60</td>\n",
              "      <td>2.25</td>\n",
              "      <td>3.25</td>\n",
              "      <td>3.25</td>\n",
              "      <td>2.25</td>\n",
              "      <td>3.13</td>\n",
              "      <td>3.60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.60</td>\n",
              "      <td>2.47</td>\n",
              "      <td>3.30</td>\n",
              "      <td>3.17</td>\n",
              "      <td>3.18</td>\n",
              "      <td>3.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.81</td>\n",
              "      <td>1.77</td>\n",
              "      <td>2.18</td>\n",
              "      <td>2.10</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.24</td>\n",
              "      <td>2.78</td>\n",
              "      <td>2.45</td>\n",
              "      <td>3.30</td>\n",
              "      <td>2.90</td>\n",
              "      <td>2.45</td>\n",
              "      <td>3.20</td>\n",
              "      <td>3.00</td>\n",
              "      <td>2.45</td>\n",
              "      <td>3.15</td>\n",
              "      <td>3.05</td>\n",
              "      <td>2.51</td>\n",
              "      <td>3.20</td>\n",
              "      <td>3.18</td>\n",
              "      <td>2.50</td>\n",
              "      <td>3.20</td>\n",
              "      <td>2.90</td>\n",
              "      <td>2.60</td>\n",
              "      <td>3.10</td>\n",
              "      <td>3.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   BbMxH  BbAvH  BbMxD  BbAvD  BbMxA  ...   WHD   WHA    VCH   VCD   VCA\n",
              "0  15.87  13.70   6.44   5.88   1.27  ...  6.00  1.22  15.00  6.00  1.25\n",
              "1   2.95   2.82   3.65   3.50   2.56  ...  3.50  2.40   2.88  3.40  2.50\n",
              "2   2.39   2.27   3.21   3.12   3.70  ...  3.20  3.30   2.25  3.10  3.70\n",
              "3   2.34   2.22   3.35   3.23   3.65  ...  3.25  3.25   2.25  3.13  3.60\n",
              "4   2.60   2.47   3.30   3.17   3.18  ...  3.20  2.90   2.60  3.10  3.00\n",
              "\n",
              "[5 rows x 32 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GG3QRJSozb3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function that creates a dataloader\n",
        "def input_fn(features , labels , training = True , batch_size = 256):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((dict(features) ,labels))\n",
        "    if training :\n",
        "     dataset = dataset.shuffle(1000).repeat()\n",
        "\n",
        "    return dataset.batch(batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQSsYV8VrAbm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_feature_columns = [tf.feature_column.numeric_column(key=key) for key in train.keys()]\n",
        "   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08Cw_KPqtMA8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "fe706e07-0137-4bf4-e624-a89def6e4d21"
      },
      "source": [
        "classifier = tf.estimator.DNNClassifier(hidden_units=[50,25],\n",
        "                                          feature_columns= my_feature_columns,\n",
        "                                          n_classes = 3                                    \n",
        "                                          )"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmprt2cxpr9\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmprt2cxpr9', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_8aI6U0tOXA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "adf7b90e-44d4-4d30-ac60-1ac6cce91e51"
      },
      "source": [
        "classifier.train(\n",
        "    input_fn= lambda: input_fn(train, target, training=True),\n",
        "    steps=5000)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/optimizer_v2/adagrad.py:103: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmprt2cxpr9/model.ckpt.\n",
            "INFO:tensorflow:loss = 1.8307753, step = 0\n",
            "INFO:tensorflow:global_step/sec: 86.6468\n",
            "INFO:tensorflow:loss = 0.9778209, step = 100 (1.160 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.722\n",
            "INFO:tensorflow:loss = 0.9381693, step = 200 (0.969 sec)\n",
            "INFO:tensorflow:global_step/sec: 98.2155\n",
            "INFO:tensorflow:loss = 0.9600536, step = 300 (1.018 sec)\n",
            "INFO:tensorflow:global_step/sec: 111.795\n",
            "INFO:tensorflow:loss = 0.9693067, step = 400 (0.896 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.539\n",
            "INFO:tensorflow:loss = 0.9323001, step = 500 (0.967 sec)\n",
            "INFO:tensorflow:global_step/sec: 110.555\n",
            "INFO:tensorflow:loss = 0.9481537, step = 600 (0.901 sec)\n",
            "INFO:tensorflow:global_step/sec: 97.7437\n",
            "INFO:tensorflow:loss = 0.92920566, step = 700 (1.024 sec)\n",
            "INFO:tensorflow:global_step/sec: 106.778\n",
            "INFO:tensorflow:loss = 0.8648769, step = 800 (0.936 sec)\n",
            "INFO:tensorflow:global_step/sec: 115.697\n",
            "INFO:tensorflow:loss = 0.9694511, step = 900 (0.868 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.413\n",
            "INFO:tensorflow:loss = 0.9400079, step = 1000 (0.977 sec)\n",
            "INFO:tensorflow:global_step/sec: 100.272\n",
            "INFO:tensorflow:loss = 0.9386575, step = 1100 (0.993 sec)\n",
            "INFO:tensorflow:global_step/sec: 122.946\n",
            "INFO:tensorflow:loss = 0.88867015, step = 1200 (0.815 sec)\n",
            "INFO:tensorflow:global_step/sec: 119.757\n",
            "INFO:tensorflow:loss = 0.9076369, step = 1300 (0.833 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.627\n",
            "INFO:tensorflow:loss = 0.9082189, step = 1400 (0.959 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.939\n",
            "INFO:tensorflow:loss = 0.96071565, step = 1500 (0.971 sec)\n",
            "INFO:tensorflow:global_step/sec: 132.179\n",
            "INFO:tensorflow:loss = 0.9200421, step = 1600 (0.754 sec)\n",
            "INFO:tensorflow:global_step/sec: 103.324\n",
            "INFO:tensorflow:loss = 0.938009, step = 1700 (0.971 sec)\n",
            "INFO:tensorflow:global_step/sec: 113.444\n",
            "INFO:tensorflow:loss = 0.95679855, step = 1800 (0.881 sec)\n",
            "INFO:tensorflow:global_step/sec: 126.203\n",
            "INFO:tensorflow:loss = 0.9607521, step = 1900 (0.789 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.592\n",
            "INFO:tensorflow:loss = 0.9520881, step = 2000 (0.975 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.989\n",
            "INFO:tensorflow:loss = 0.98215675, step = 2100 (0.943 sec)\n",
            "INFO:tensorflow:global_step/sec: 122.318\n",
            "INFO:tensorflow:loss = 0.89721537, step = 2200 (0.818 sec)\n",
            "INFO:tensorflow:global_step/sec: 106.041\n",
            "INFO:tensorflow:loss = 0.9084563, step = 2300 (0.942 sec)\n",
            "INFO:tensorflow:global_step/sec: 101.336\n",
            "INFO:tensorflow:loss = 0.92889035, step = 2400 (0.987 sec)\n",
            "INFO:tensorflow:global_step/sec: 117.752\n",
            "INFO:tensorflow:loss = 0.90242124, step = 2500 (0.853 sec)\n",
            "INFO:tensorflow:global_step/sec: 115.445\n",
            "INFO:tensorflow:loss = 0.88960356, step = 2600 (0.864 sec)\n",
            "INFO:tensorflow:global_step/sec: 116.568\n",
            "INFO:tensorflow:loss = 0.92597663, step = 2700 (0.857 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.305\n",
            "INFO:tensorflow:loss = 0.9210519, step = 2800 (0.957 sec)\n",
            "INFO:tensorflow:global_step/sec: 114.748\n",
            "INFO:tensorflow:loss = 0.93687546, step = 2900 (0.875 sec)\n",
            "INFO:tensorflow:global_step/sec: 111.649\n",
            "INFO:tensorflow:loss = 0.9007503, step = 3000 (0.893 sec)\n",
            "INFO:tensorflow:global_step/sec: 114.776\n",
            "INFO:tensorflow:loss = 0.88435245, step = 3100 (0.870 sec)\n",
            "INFO:tensorflow:global_step/sec: 104.043\n",
            "INFO:tensorflow:loss = 0.8883941, step = 3200 (0.964 sec)\n",
            "INFO:tensorflow:global_step/sec: 99.2034\n",
            "INFO:tensorflow:loss = 0.929211, step = 3300 (1.005 sec)\n",
            "INFO:tensorflow:global_step/sec: 115.217\n",
            "INFO:tensorflow:loss = 0.9459318, step = 3400 (0.872 sec)\n",
            "INFO:tensorflow:global_step/sec: 97.8237\n",
            "INFO:tensorflow:loss = 0.9424716, step = 3500 (1.021 sec)\n",
            "INFO:tensorflow:global_step/sec: 99.1852\n",
            "INFO:tensorflow:loss = 0.9374188, step = 3600 (1.005 sec)\n",
            "INFO:tensorflow:global_step/sec: 99.1141\n",
            "INFO:tensorflow:loss = 0.9551263, step = 3700 (1.009 sec)\n",
            "INFO:tensorflow:global_step/sec: 95.9208\n",
            "INFO:tensorflow:loss = 0.8813001, step = 3800 (1.043 sec)\n",
            "INFO:tensorflow:global_step/sec: 101.358\n",
            "INFO:tensorflow:loss = 0.92500186, step = 3900 (0.986 sec)\n",
            "INFO:tensorflow:global_step/sec: 100.332\n",
            "INFO:tensorflow:loss = 0.86320823, step = 4000 (0.997 sec)\n",
            "INFO:tensorflow:global_step/sec: 113.166\n",
            "INFO:tensorflow:loss = 0.92711926, step = 4100 (0.886 sec)\n",
            "INFO:tensorflow:global_step/sec: 119.277\n",
            "INFO:tensorflow:loss = 0.91672456, step = 4200 (0.838 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.288\n",
            "INFO:tensorflow:loss = 0.89208126, step = 4300 (0.951 sec)\n",
            "INFO:tensorflow:global_step/sec: 114.117\n",
            "INFO:tensorflow:loss = 0.9241688, step = 4400 (0.876 sec)\n",
            "INFO:tensorflow:global_step/sec: 101.627\n",
            "INFO:tensorflow:loss = 0.8712915, step = 4500 (0.981 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.288\n",
            "INFO:tensorflow:loss = 0.888569, step = 4600 (0.981 sec)\n",
            "INFO:tensorflow:global_step/sec: 101.233\n",
            "INFO:tensorflow:loss = 0.88649553, step = 4700 (0.985 sec)\n",
            "INFO:tensorflow:global_step/sec: 107.148\n",
            "INFO:tensorflow:loss = 0.91696346, step = 4800 (0.936 sec)\n",
            "INFO:tensorflow:global_step/sec: 100.48\n",
            "INFO:tensorflow:loss = 0.9038339, step = 4900 (0.995 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 5000 into /tmp/tmprt2cxpr9/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 0.8591632.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifierV2 at 0x7f3b4a0753c8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpxSjySounEI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "outputId": "4ae52a1d-9748-49f2-efa8-83ff1420224d"
      },
      "source": [
        "classifier.evaluate( input_fn=lambda: input_fn(train , target , training=False) )"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-01-15T15:09:56Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmprt2cxpr9/model.ckpt-5000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Inference Time : 0.34737s\n",
            "INFO:tensorflow:Finished evaluation at 2020-01-15-15:09:57\n",
            "INFO:tensorflow:Saving dict for global step 5000: accuracy = 0.55789477, average_loss = 0.9047844, global_step = 5000, loss = 0.9246965\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: /tmp/tmprt2cxpr9/model.ckpt-5000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.55789477,\n",
              " 'average_loss': 0.9047844,\n",
              " 'global_step': 5000,\n",
              " 'loss': 0.9246965}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEPj4Z8swGxV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6b905c87-d634-4061-fc62-1dba5569f51c"
      },
      "source": [
        "classifier.train(\n",
        "    input_fn= lambda: input_fn(train, target, training=True),\n",
        "    steps=5000)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmprt2cxpr9/model.ckpt-5000\n",
            "WARNING:tensorflow:From /tensorflow-2.1.0/python3.6/tensorflow_core/python/training/saver.py:1069: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file utilities to get mtimes.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 5000 into /tmp/tmprt2cxpr9/model.ckpt.\n",
            "INFO:tensorflow:loss = 0.90583616, step = 5000\n",
            "INFO:tensorflow:global_step/sec: 91.204\n",
            "INFO:tensorflow:loss = 0.914001, step = 5100 (1.098 sec)\n",
            "INFO:tensorflow:global_step/sec: 98.2592\n",
            "INFO:tensorflow:loss = 0.9273238, step = 5200 (1.020 sec)\n",
            "INFO:tensorflow:global_step/sec: 100.595\n",
            "INFO:tensorflow:loss = 0.9334596, step = 5300 (0.991 sec)\n",
            "INFO:tensorflow:global_step/sec: 129.995\n",
            "INFO:tensorflow:loss = 0.8944471, step = 5400 (0.770 sec)\n",
            "INFO:tensorflow:global_step/sec: 120.02\n",
            "INFO:tensorflow:loss = 0.91828644, step = 5500 (0.835 sec)\n",
            "INFO:tensorflow:global_step/sec: 101.034\n",
            "INFO:tensorflow:loss = 0.92310166, step = 5600 (0.991 sec)\n",
            "INFO:tensorflow:global_step/sec: 99.6303\n",
            "INFO:tensorflow:loss = 0.9090289, step = 5700 (1.002 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.255\n",
            "INFO:tensorflow:loss = 0.88855684, step = 5800 (0.949 sec)\n",
            "INFO:tensorflow:global_step/sec: 99.7503\n",
            "INFO:tensorflow:loss = 0.8939441, step = 5900 (1.002 sec)\n",
            "INFO:tensorflow:global_step/sec: 124.288\n",
            "INFO:tensorflow:loss = 0.9309861, step = 6000 (0.807 sec)\n",
            "INFO:tensorflow:global_step/sec: 100.436\n",
            "INFO:tensorflow:loss = 0.8999183, step = 6100 (0.993 sec)\n",
            "INFO:tensorflow:global_step/sec: 123.406\n",
            "INFO:tensorflow:loss = 0.8968203, step = 6200 (0.813 sec)\n",
            "INFO:tensorflow:global_step/sec: 98.0251\n",
            "INFO:tensorflow:loss = 0.87520075, step = 6300 (1.019 sec)\n",
            "INFO:tensorflow:global_step/sec: 100.944\n",
            "INFO:tensorflow:loss = 0.9414573, step = 6400 (0.990 sec)\n",
            "INFO:tensorflow:global_step/sec: 100.037\n",
            "INFO:tensorflow:loss = 0.8905758, step = 6500 (1.000 sec)\n",
            "INFO:tensorflow:global_step/sec: 97.8559\n",
            "INFO:tensorflow:loss = 0.89744323, step = 6600 (1.022 sec)\n",
            "INFO:tensorflow:global_step/sec: 98.6587\n",
            "INFO:tensorflow:loss = 0.88289267, step = 6700 (1.014 sec)\n",
            "INFO:tensorflow:global_step/sec: 117.227\n",
            "INFO:tensorflow:loss = 0.9071127, step = 6800 (0.853 sec)\n",
            "INFO:tensorflow:global_step/sec: 99.1388\n",
            "INFO:tensorflow:loss = 0.90730643, step = 6900 (1.009 sec)\n",
            "INFO:tensorflow:global_step/sec: 101.177\n",
            "INFO:tensorflow:loss = 0.91767555, step = 7000 (0.988 sec)\n",
            "INFO:tensorflow:global_step/sec: 117.167\n",
            "INFO:tensorflow:loss = 0.9012884, step = 7100 (0.854 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.63\n",
            "INFO:tensorflow:loss = 0.8929055, step = 7200 (0.974 sec)\n",
            "INFO:tensorflow:global_step/sec: 106.155\n",
            "INFO:tensorflow:loss = 0.9287474, step = 7300 (0.943 sec)\n",
            "INFO:tensorflow:global_step/sec: 117.199\n",
            "INFO:tensorflow:loss = 0.9073248, step = 7400 (0.856 sec)\n",
            "INFO:tensorflow:global_step/sec: 124.494\n",
            "INFO:tensorflow:loss = 0.9312701, step = 7500 (0.803 sec)\n",
            "INFO:tensorflow:global_step/sec: 101.072\n",
            "INFO:tensorflow:loss = 0.88507724, step = 7600 (0.990 sec)\n",
            "INFO:tensorflow:global_step/sec: 100.265\n",
            "INFO:tensorflow:loss = 0.9021416, step = 7700 (0.995 sec)\n",
            "INFO:tensorflow:global_step/sec: 112.546\n",
            "INFO:tensorflow:loss = 0.8907605, step = 7800 (0.887 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.585\n",
            "INFO:tensorflow:loss = 0.92885363, step = 7900 (0.977 sec)\n",
            "INFO:tensorflow:global_step/sec: 101.115\n",
            "INFO:tensorflow:loss = 0.91125894, step = 8000 (0.987 sec)\n",
            "INFO:tensorflow:global_step/sec: 101.856\n",
            "INFO:tensorflow:loss = 0.8803029, step = 8100 (0.983 sec)\n",
            "INFO:tensorflow:global_step/sec: 112.075\n",
            "INFO:tensorflow:loss = 0.8984685, step = 8200 (0.893 sec)\n",
            "INFO:tensorflow:global_step/sec: 99.326\n",
            "INFO:tensorflow:loss = 0.8739017, step = 8300 (1.004 sec)\n",
            "INFO:tensorflow:global_step/sec: 102.12\n",
            "INFO:tensorflow:loss = 0.9014646, step = 8400 (0.979 sec)\n",
            "INFO:tensorflow:global_step/sec: 98.5127\n",
            "INFO:tensorflow:loss = 0.8718146, step = 8500 (1.016 sec)\n",
            "INFO:tensorflow:global_step/sec: 97.2094\n",
            "INFO:tensorflow:loss = 0.8997468, step = 8600 (1.028 sec)\n",
            "INFO:tensorflow:global_step/sec: 101.504\n",
            "INFO:tensorflow:loss = 0.8842416, step = 8700 (0.985 sec)\n",
            "INFO:tensorflow:global_step/sec: 107.6\n",
            "INFO:tensorflow:loss = 0.9164295, step = 8800 (0.932 sec)\n",
            "INFO:tensorflow:global_step/sec: 105.935\n",
            "INFO:tensorflow:loss = 0.91786885, step = 8900 (0.943 sec)\n",
            "INFO:tensorflow:global_step/sec: 99.6929\n",
            "INFO:tensorflow:loss = 0.9127475, step = 9000 (1.005 sec)\n",
            "INFO:tensorflow:global_step/sec: 118.384\n",
            "INFO:tensorflow:loss = 0.88709474, step = 9100 (0.845 sec)\n",
            "INFO:tensorflow:global_step/sec: 106.691\n",
            "INFO:tensorflow:loss = 0.9228369, step = 9200 (0.934 sec)\n",
            "INFO:tensorflow:global_step/sec: 99.1583\n",
            "INFO:tensorflow:loss = 0.9021654, step = 9300 (1.008 sec)\n",
            "INFO:tensorflow:global_step/sec: 114.406\n",
            "INFO:tensorflow:loss = 0.9065239, step = 9400 (0.876 sec)\n",
            "INFO:tensorflow:global_step/sec: 99.5646\n",
            "INFO:tensorflow:loss = 0.8650336, step = 9500 (1.003 sec)\n",
            "INFO:tensorflow:global_step/sec: 111.018\n",
            "INFO:tensorflow:loss = 0.9235425, step = 9600 (0.901 sec)\n",
            "INFO:tensorflow:global_step/sec: 101.055\n",
            "INFO:tensorflow:loss = 0.9275561, step = 9700 (0.993 sec)\n",
            "INFO:tensorflow:global_step/sec: 117.414\n",
            "INFO:tensorflow:loss = 0.83039296, step = 9800 (0.851 sec)\n",
            "INFO:tensorflow:global_step/sec: 100.5\n",
            "INFO:tensorflow:loss = 0.9065265, step = 9900 (0.993 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/tmprt2cxpr9/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 0.92672014.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifierV2 at 0x7f3b4a0753c8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ck4tOHKHxQY4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "outputId": "2ae4910f-c44e-430a-d189-f709b5ecaeb7"
      },
      "source": [
        "classifier.evaluate(lambda : input_fn(train , target , training = False))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-01-15T15:26:28Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmprt2cxpr9/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Inference Time : 0.35022s\n",
            "INFO:tensorflow:Finished evaluation at 2020-01-15-15:26:28\n",
            "INFO:tensorflow:Saving dict for global step 10000: accuracy = 0.5736842, average_loss = 0.89654976, global_step = 10000, loss = 0.91657555\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 10000: /tmp/tmprt2cxpr9/model.ckpt-10000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.5736842,\n",
              " 'average_loss': 0.89654976,\n",
              " 'global_step': 10000,\n",
              " 'loss': 0.91657555}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKVNW07v0Csz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuqvvikI565I",
        "colab_type": "text"
      },
      "source": [
        "# Linear Estimator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2Ai5zUb590j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}